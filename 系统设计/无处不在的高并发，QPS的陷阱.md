# 一、引言：为什么我们总在谈高并发？

如果你最近参加过后端开发岗位的面试，极大概率会遇到这样的问题：

- 如果系统的 QPS 突然到 10万，你会怎么设计？
- 秒杀场景你会怎么设计？
- 并发请求量过高，数据库顶不住怎么办？
- 高并发场景下如何保证系统稳定性？

这几乎成为技术面试的保留节目，当一个面试官提到MySQL、Redis或者系统设计时，极大可能性会提到这样的系统设计题。

但一个很奇怪的现象是：**真正在线上工作的人，反而很少真的会遇到这些极端的场景**。

那么问题来了——为什么我们总是在谈高并发？高并发到底是一个什么类型的问题？要怎么解决？

## 高并发，正在被神化

无论是在大众的技术社区，还是私下中的技术面试、技术讨论中，高并发几乎成为了一种能力标签：

- 能讲清楚高并发 → 技术强
- 写过秒杀系统 → 架构能力好
- 能画出复杂的机构图 → 有经验

但现实中，大多是系统是这样的情况：

- 日常 QPS 可能只有几十到几百
- 峰值流量可预测
- 核心瓶颈往往不在并发，而在设计

可我们仍然执着于问，如果突然来 100万 QPS 呢？

这类问题本身就带着一个默认的前提：你的系统必须在任何情况下都保持完美运行。

然而，现实工程从来不是这样。无论国内还是国外，无论多高的用户量级，都不敢保证自己的系统能够在任何情况下都保持完美运行。

但是，就是存在一部分人，会让你在短短几分钟内，在一个几乎完全架空的场景下（如一个订单表、一个用户表，设计一个秒杀系统）设计一个“完美”的系统。

## 我们谈的高并发，大多数情况下并不存在

在真实的业务中，高并发通常有三个前提条件：

1. 用户量级足够大
2. 用户行为高度集中
3. 请求路径无法削峰或缓冲

但这三个条件，很少同时成立。

举一个简单的例子：

- 一个日活 10万+ 的系统
- 平均每人每天有 20 次操作
- 总请求数 ≈ 200万/天
- 平均 QPS ≈ 23

哪怕在高峰期放大 10 倍，也不过 200 多的 QPS

这种情况，距离所谓的“高并发系统”，其实还非常遥远。

但是在面试中，我们往往会被带入这样一个假设：

> 现在你的系统每秒有 10 万请求……

这个前提本身，往往就是未经验证的。

## 高并发问题，很多时候是被“问”出来的

更现实的一点是：很多高并发问题，不是业务带来的，而是面试设计出来的。

> 更有甚者，你想基于业务和他聊，他告诉你只想要和你聊相关的技术问题。

比如：

- 不考虑缓存，直接问数据库怎么扛
- 不允许降级，要求数据的强一致性
- 不允许一步，要求实时返回
- 不允许失败，要求 100% 成功

在这样一系列严苛的前提下，任何系统都会崩溃。从此，软件工程不存在了。

往往令人绷不住的是，你在面试的时候被这样一番拷打，在结束之后想要从网上或者GPT中获取这个抽象问题的答案。但是往往得不到你想要的结果，GPT甚至还会告诉你和这个问题偏离很远的答案。

这是因为，在真实的工程中，往往是和面试相反的，在这里：

- 可以缓存
- 可以有延迟
- 可以失败然后重试
- 可以补偿
- 可以牺牲掉一部分一致性

于是你发现了一个很有意思的现象：

> **显示系统解决问题的方式，和面试中的标准答案，往往是相反的。**

## 我们真正困惑的，其实不是技术

很多人以为自己搞不懂高并发，是因为：

- 中间件不熟
- 架构经验不足
- 底层原理没掌握
- ……

但实际上，真正让人困惑的，是这三个问题：

1. 这个场景真的会有这么高的并发吗？
2. 如果扛不住，后果是什么？
3. 能不能通过业务方式规避，而不是技术规避？

如果这三个问题不明确，讨论高并发无疑是纸上谈兵，这场面试将变成纯粹的技术体操。

## 高并发，本质上是一个取舍问题

这将是本文最核心的观点之一：

> 高并发从来不是“能不能扛住”的问题，而是“值不值得扛”的问题。

但凡是参与过工作的同学一定会有这样的感受，显示的系统永远在做的只有一件事——权衡：

- 性能 VS 成本
- 一致性 VS 可用性
- 实时性 VS 稳定性
- 用户体验 VS 系统复杂度

而所谓的 “高并发设计”，本质上就是在这些维度之间做取舍。

## 通过本文，你能得到什么

我写这篇文章，并不是为了教你如何写一个秒杀系统、如何支撑起百万 QPS、如何设计一个复杂架构。

而是想要回答一个更本质的问题：**当我们在谈高并发时，我们到底在谈什么？**

**是流量？是性能？是架构？还是我们对系统的认知？**

接下来的内容，我会从一个经常被误用的概念讲起——QPS。正是因为他，让很多人包括笔者自己，误认为自己理解了高并发。

# 二、QPS 的陷阱：你以为在谈性能，其实什么都没说明

如果说 “高并发” 是一个被滥用的概念，那么 QPS 就是这个概念中最容易被误解、也最容易被滥用的指标。

几乎每一次关于高并发的讨论，都会从一句话开始：

> 我们这个系统要支持 XX 万的 QPS。

这句话听起来很专业，但实际上，它几乎什么信息都没有提供。

## QPS 是一个 “看起来很努力” 的指标

QPS (Queries Per Second) 本质上只是一个统计值，它描述的是：**单元时间内，系统完成多少次请求**。

注意这里的关键词是 “完成”。

它不关心这些请求花了多久，也不关心系统付出多少代价，更不关心这戏请求是均匀发生的，还是在某一个瞬间集中爆发的。

换句话说，QPS 只描述了结果，而没有描述过程。

这也是为什么同样是 “1万 QPS”，在不同的系统中，含义可能完全不同。

一个接口如果 5ms 就能返回，那么 1万 QPS 可能只是几百个并发；而如果一个接口需要 500ms 才能返回，那 1万 QPS 意味着系统同时堆着五千个请求。

这两个系统，在工程复杂度啊上，几乎不在一个量级。

但是在面试的时候，它们往往被当成一件事来讨论。

## 真正决定系统压力的，从来不是 QPS

只需要记住一个公式：

> **并发数 ≈ QPS × 平均响应时间（RT）** 

这是一个极其朴素，但极其重要的关系。他结识了一个经常被忽略的事实：

> 系统不是被请求数量压垮的，而是被 “同时存在的请求” 压垮的。

当一个请求进入系统，它并不会立即消失，而是会占用以下资源：

- 一个 goroutine / 线程
- 一段内存
- 一次数据库连接
- 若干上下文切换成本

只要它没有返回，这些资源就一直被占着。

所以，高并发的本质不是 “请求多”，而是 **在同一时间，有太多事情等着被处理**。

这也是为什么很多系统在 QPS 看起来并不高的时候，仍然会出现：

- RT 飙升
- 线程池打满
- 数据库连接耗尽
- 服务雪崩

因为真正的眼里，并不体现在 QPS 上，而体现在 “积压” 上。

## 一个被忽略的事实：QPS 高，反而可能是件好事

这是一个非常反直觉的观点。很多人会下意识地认为 “QPS 高 = 系统压力大 = 风险高”。但在很多情况下，恰恰相反。

如果一个系统：

- QPS 很高
- RT 很低
- 并发数可控
- 资源使用稳定

这说明它的处理路径非常短，系统效率很高。

相反，真正危险的系统往往是：

- QPS 很低
- 但 RT 很长
- 并发持续堆积
- 资源慢慢被吃满

这种系统，往往死得悄无声息。他不会瞬间崩溃，而是慢慢变慢，慢慢阻塞，直到某个临界点彻底失控。

从这个角度来看，高 QPS 本身并不可怕，**可怕的是你不知道这个 QPS 背后意味着多少并发**。

## 真正应该关注的是 “分布” 而不是 “平均值”

另一个常见误区是：只看平均响应时间。

平均值是一个极具欺骗性的指标。

假设一个系统：

- 99% 的请求在 20ms 内完成
- 1% 的请求需要 3 秒

那么它的平均 RT 可能只有几十毫秒，看起来非常健康。

但对于用户来说，那 1% 的请求就是：

- 页面卡死 
- 接口超时
- 操作失败
- 投诉出现

从用户视角看，系统是“有问题的”。

这也是为什么在真正的高并发系统中，工程师更关心：

- P95
- P99
- 甚至 P999

因为这些指标反映的不是“系统大多数时候怎么样”，而是——**系统最糟糕的时候会发生什么**。

而高并发，往往就是在这些最糟糕的时刻出现的。

## QPS 掩盖了一个更关键的问题：系统是否可控

当我们只盯着 QPS 的时候，很容易忽略一个更重要的问题度：当系统开始变慢时，你是否还有控制权？

一个真正危险的系统，往往具备以下特征：

- 请求持续涌入
- 没有限流
- 没有拒绝策略
- 没有降级
- 没有超时
- 没有熔断

这种系统在低负载下看起来 “性能很好”，但一旦超过临界点，就会迅速进入不可逆的崩溃状态。

而一个成熟的系统，反而会在 “扛不住之前” 就主动示弱：

- 主动丢弃非核心请求
- 主动降低服务质量
- 主动延迟处理
- 主动返回兜底策略

这也是为什么说：**高并发系统拼的不是极限性能，而是失控之前的自我保护能力**。

## 回到本质：QPS 只是结果，不是能力  

> QPS 不是系统能力的体现，它只是系统状态的一个结果。

真正决定系统能否承受高并发的，从来不是一个数字，而是：

- 你的请求是否可以被削峰
- 你的链路是否足够短
- 你的失败是否可控
- 你的系统是否知道什么时候该放弃

也正因为如此，脱离业务背景谈 QPS，本身就是一种误导。

# 三、我们到底在衡量什么？

如果说上一节是在拆掉“QPS 等于高并发”的错觉，那么这一节要做的事情只有一个：

> **把“高并发”从一个模糊的印象，拆解成几个可以被真正理解的工程指标。**

因为在真实系统中，没有任何一个工程师是靠一个数字在做决策的。

真正影响系统设计的，是一组彼此制约、相互影响的指标。

而 QPS，只是其中最表层的一个。

## 并发

很多人会把“并发”理解成一种能力：“这个系统能抗多少并发？”

但在工程语境下，并发从来不是能力，而是一种**状态**。

它描述的不是系统能做什么，而是——**此时此刻，系统里有多少请求还没处理完。**

这也是为什么并发这个词，本质上永远和三件事绑定在一起：

- 活跃请求数
- 资源占用情况
- 上下文切换成本

每一个没有完成的请求，都会实实在在地占用资源：一个 goroutine、一段内存、一次数据库连接、一次锁竞争。

所以，并发高不高，决定的不是系统“能处理多少请求”，而是——**系统同时要扛住多少压力。**

这也是为什么可以说：

> **并发决定了你需要多少资源，而不是你能处理多少请求。**

一个系统完全可能 QPS 不高，但并发极高；也完全可能 QPS 很高，但并发始终可控。

真正拉开差距的，从来不是“请求总量”，而是“请求在系统里停留多久”。

## RT / P99：被忽视的核心指标

如果说并发是系统的“承压状态”，

那 RT（响应时间）就是这个状态最直观的外在表现。

但问题在于，大多数人谈 RT，只看平均值。

平均值是一个非常“温柔”的指标，它会抹平所有问题。

一个系统哪怕存在少量 2 秒、3 秒的慢请求，只要比例足够低，平均 RT 看起来依然会很漂亮。

可现实是——用户体验从来不是由平均值决定的。

当用户觉得系统“卡了”，往往不是因为它慢了 10ms，而是因为某一次请求突然卡住了。

这也是为什么在高并发系统里，真正有意义的指标是：

- P95    
- P99    
- 甚至 P999    

它们代表的是：**在最糟糕的情况下，系统还能不能接受。**

很多系统的失败，并不是因为整体性能不够好，而是因为极少数请求把资源拖死了。

所以才会有这样一句话：

> 系统不是慢在平均值，而是死在极端值。
> 用户感知的从来不是 P50，而是那一次卡死。

当你开始关注 P99，而不是平均 RT 时，你才真正开始站在“系统稳定性”的视角看问题。

## TPS：业务视角下的真实指标

如果说 QPS 更偏技术视角，那么 TPS 更接近业务视角。

QPS 统计的是接口调用次数，而 TPS 统计的，是**业务动作的完成次数**。

一个下单操作，可能包含：

- 参数校验    
- 库存检查
- 价格计算
- 订单写库
- 消息投递
- 状态回调

从 QPS 角度看，这是多个请求；但从业务角度看，它只是一次交易。

这也是为什么在复杂系统中，单纯讨论 QPS 往往没有意义。

因为你永远无法从一个 QPS 数字中，看出：

- 一次请求背后调用了多少服务    
- 消耗了多少数据库资源
- 触发了多少异步逻辑

所以才会有这样一个更贴近现实的判断方式：

  > QPS 描述接口，TPS 描述业务。
> 一个 TPS 背后，往往是多个接口、多个系统的协作。

当你开始用 TPS 去思考问题时，你关注的就不再是“接口快不快”，而是“这件事做完要付出多大代价”。

这本身，就是一种视角的升级。

## **3.4 吞吐、并发、延迟的关系**

如果把系统比作一条公路，那么这三个概念的关系其实非常直观：

- 吞吐量，是单位时间通过的车辆数    
- 并发数，是路上同时存在的车辆
- 延迟，是从上路到下路花的时间

你可以让路很宽，让车跑得多；也可以让车开得很快，但路上车不多；但你很难在资源有限的情况下，同时做到三者都极致。

这也是很多系统在高负载下表现异常的根本原因。

  当吞吐被不断推高，而并发又持续累积时，延迟就会开始不可控地上升。

于是你会看到一个非常典型的现象：

- 系统“还能用”    
- QPS“还能跑”
- 但用户体验已经明显下降

这并不是偶然，而是系统到达物理边界后的必然结果。

所以才会有这样一句话：

> 吞吐是车流量，并发是路上的车，延迟是堵车时间。
> 高吞吐的系统，不一定是低延迟的系统。

理解了这一点，你就会明白——所谓 “高并发系统设计”，本质上从来不是堆性能，而是管理拥堵。

# 四、真正的高并发来自哪里？

如果前面几个小节都是在拆概念，那门从这一节开始，我们要把视角拉回到现实的系统中。

一个很重要，但是经常被忽略的事实是：**绝大多数高并发问题，并不是“流量太大”了，而是“流量在不该集中的地方集中起来了”**。

换句话说，高并发往往不是自然产生的，而是被某种行为放大的结果。

## 用户行为带来的并发

在所有高并发的场景中，最容易被理解的，往往也是最容易被高估的，就是用户行为。

秒杀、抢购、活动开始瞬间，这些场景看起来天然和 “高并发” 绑定在一起。

但是你仔细想想，会发现一个很有意思的现象：这些场景的本质，并不是用户足够多，而是用户在同一时间在做同一件事。

人类的行为具有极强的同步性。

当一个活动被定义为“10 点开始”，那就意味着：

- 9:59 几乎没人点
- 10:00 大量请求同时涌入
- 10:01 热度迅速下降

从系统角度看，这是一种非常极端的访问模式：请求不是均匀分布的，而是被强行压缩到了一个极短的时间窗口内。

也正因为如此，这类场景才反复被拿来当作 “高并发” 的代表。

但是问题在于，这种并发其实是人为制造的。要解决这种问题，其实只需要稍微换一种方式，比如：

- 引入排队机制
- 提前发放资格
- 使用随机延迟
- 分批放量

你会发现，并发峰值会立刻下降一个数量级。

所以很多时候，高并发并不是技术问题，而是产品设计的问题。也正因如此，才会有这样一句话：**用户不会平均访问，他们只会一起点。**

## 系统行为制造的并发

如果说用户行为带来的并发还算 ”合理“，那真正危险的高并发，往往是系统自己。

这一点，

# 五、高并发系统真正要解决的三个问题


# 六、从工程角度看，高并发的解决手段


# 七、回到现实 —— 我们该如何应对面试中的“高并发”问题？


# 八、总结：高并发不是技术问题，而是认知问题

