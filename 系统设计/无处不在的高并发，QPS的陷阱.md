# 一、引言：为什么我们总在谈高并发？

如果你最近参加过后端开发岗位的面试，极大概率会遇到这样的问题：

- 如果系统的 QPS 突然到 10万，你会怎么设计？
- 秒杀场景你会怎么设计？
- 并发请求量过高，数据库顶不住怎么办？
- 高并发场景下如何保证系统稳定性？

这几乎成为技术面试的保留节目，当一个面试官提到MySQL、Redis或者系统设计时，极大可能性会提到这样的系统设计题。

但一个很奇怪的现象是：**真正在线上工作的人，反而很少真的会遇到这些极端的场景**。

那么问题来了——为什么我们总是在谈高并发？高并发到底是一个什么类型的问题？要怎么解决？

## 高并发，正在被神化

无论是在大众的技术社区，还是私下中的技术面试、技术讨论中，高并发几乎成为了一种能力标签：

- 能讲清楚高并发 → 技术强
- 写过秒杀系统 → 架构能力好
- 能画出复杂的机构图 → 有经验

但现实中，大多是系统是这样的情况：

- 日常 QPS 可能只有几十到几百
- 峰值流量可预测
- 核心瓶颈往往不在并发，而在设计

可我们仍然执着于问，如果突然来 100万 QPS 呢？

这类问题本身就带着一个默认的前提：你的系统必须在任何情况下都保持完美运行。

然而，现实工程从来不是这样。无论国内还是国外，无论多高的用户量级，都不敢保证自己的系统能够在任何情况下都保持完美运行。

但是，就是存在一部分人，会让你在短短几分钟内，在一个几乎完全架空的场景下（如一个订单表、一个用户表，设计一个秒杀系统）设计一个“完美”的系统。

## 我们谈的高并发，大多数情况下并不存在

在真实的业务中，高并发通常有三个前提条件：

1. 用户量级足够大
2. 用户行为高度集中
3. 请求路径无法削峰或缓冲

但这三个条件，很少同时成立。

举一个简单的例子：

- 一个日活 10万+ 的系统
- 平均每人每天有 20 次操作
- 总请求数 ≈ 200万/天
- 平均 QPS ≈ 23

哪怕在高峰期放大 10 倍，也不过 200 多的 QPS

这种情况，距离所谓的“高并发系统”，其实还非常遥远。

但是在面试中，我们往往会被带入这样一个假设：

> 现在你的系统每秒有 10 万请求……

这个前提本身，往往就是未经验证的。

## 高并发问题，很多时候是被“问”出来的

更现实的一点是：很多高并发问题，不是业务带来的，而是面试设计出来的。

> 更有甚者，你想基于业务和他聊，他告诉你只想要和你聊相关的技术问题。

比如：

- 不考虑缓存，直接问数据库怎么扛
- 不允许降级，要求数据的强一致性
- 不允许一步，要求实时返回
- 不允许失败，要求 100% 成功

在这样一系列严苛的前提下，任何系统都会崩溃。从此，软件工程不存在了。

往往令人绷不住的是，你在面试的时候被这样一番拷打，在结束之后想要从网上或者GPT中获取这个抽象问题的答案。但是往往得不到你想要的结果，GPT甚至还会告诉你和这个问题偏离很远的答案。

这是因为，在真实的工程中，往往是和面试相反的，在这里：

- 可以缓存
- 可以有延迟
- 可以失败然后重试
- 可以补偿
- 可以牺牲掉一部分一致性

于是你发现了一个很有意思的现象：

> **显示系统解决问题的方式，和面试中的标准答案，往往是相反的。**

## 我们真正困惑的，其实不是技术

很多人以为自己搞不懂高并发，是因为：

- 中间件不熟
- 架构经验不足
- 底层原理没掌握
- ……

但实际上，真正让人困惑的，是这三个问题：

1. 这个场景真的会有这么高的并发吗？
2. 如果扛不住，后果是什么？
3. 能不能通过业务方式规避，而不是技术规避？

如果这三个问题不明确，讨论高并发无疑是纸上谈兵，这场面试将变成纯粹的技术体操。

## 高并发，本质上是一个取舍问题

这将是本文最核心的观点之一：

> 高并发从来不是“能不能扛住”的问题，而是“值不值得扛”的问题。

但凡是参与过工作的同学一定会有这样的感受，显示的系统永远在做的只有一件事——权衡：

- 性能 VS 成本
- 一致性 VS 可用性
- 实时性 VS 稳定性
- 用户体验 VS 系统复杂度

而所谓的 “高并发设计”，本质上就是在这些维度之间做取舍。

## 通过本文，你能得到什么

我写这篇文章，并不是为了教你如何写一个秒杀系统、如何支撑起百万 QPS、如何设计一个复杂架构。

而是想要回答一个更本质的问题：**当我们在谈高并发时，我们到底在谈什么？**

**是流量？是性能？是架构？还是我们对系统的认知？**

接下来的内容，我会从一个经常被误用的概念讲起——QPS。正是因为他，让很多人包括笔者自己，误认为自己理解了高并发。

# 二、QPS 的陷阱：你以为在谈性能，其实什么都没说明

如果说 “高并发” 是一个被滥用的概念，那么 QPS 就是这个概念中最容易被误解、也最容易被滥用的指标。

几乎每一次关于高并发的讨论，都会从一句话开始：

> 我们这个系统要支持 XX 万的 QPS。

这句话听起来很专业，但实际上，它几乎什么信息都没有提供。

## QPS 是一个 “看起来很努力” 的指标

QPS (Queries Per Second) 本质上只是一个统计值，它描述的是：**单元时间内，系统完成多少次请求**。

注意这里的关键词是 “完成”。

它不关心这些请求花了多久，也不关心系统付出多少代价，更不关心这戏请求是均匀发生的，还是在某一个瞬间集中爆发的。

换句话说，QPS 只描述了结果，而没有描述过程。

这也是为什么同样是 “1万 QPS”，在不同的系统中，含义可能完全不同。

一个接口如果 5ms 就能返回，那么 1万 QPS 可能只是几百个并发；而如果一个接口需要 500ms 才能返回，那 1万 QPS 意味着系统同时堆着五千个请求。

这两个系统，在工程复杂度啊上，几乎不在一个量级。

但是在面试的时候，它们往往被当成一件事来讨论。

## 真正决定系统压力的，从来不是 QPS

只需要记住一个公式：

> **并发数 ≈ QPS × 平均响应时间（RT）** 

这是一个极其朴素，但极其重要的关系。他结识了一个经常被忽略的事实：

> 系统不是被请求数量压垮的，而是被 “同时存在的请求” 压垮的。

当一个请求进入系统，它并不会立即消失，而是会占用以下资源：

- 一个 goroutine / 线程
- 一段内存
- 一次数据库连接
- 若干上下文切换成本

只要它没有返回，这些资源就一直被占着。

所以，高并发的本质不是 “请求多”，而是 **在同一时间，有太多事情等着被处理**。

这也是为什么很多系统在 QPS 看起来并不高的时候，仍然会出现：

- RT 飙升
- 线程池打满
- 数据库连接耗尽
- 服务雪崩

因为真正的眼里，并不体现在 QPS 上，而体现在 “积压” 上。

## 一个被忽略的事实：QPS 高，反而可能是件好事

这是一个非常反直觉的观点。很多人会下意识地认为 “QPS 高 = 系统压力大 = 风险高”。但在很多情况下，恰恰相反。

如果一个系统：

- QPS 很高
- RT 很低
- 并发数可控
- 资源使用稳定

这说明它的处理路径非常短，系统效率很高。

相反，真正危险的系统往往是：

- QPS 很低
- 但 RT 很长
- 并发持续堆积
- 资源慢慢被吃满

这种系统，往往死得悄无声息。他不会瞬间崩溃，而是慢慢变慢，慢慢阻塞，直到某个临界点彻底失控。

从这个角度来看，高 QPS 本身并不可怕，**可怕的是你不知道这个 QPS 背后意味着多少并发**。

## 真正应该关注的是 “分布” 而不是 “平均值”

另一个常见误区是：只看平均响应时间。

平均值是一个极具欺骗性的指标。

假设一个系统：

- 99% 的请求在 20ms 内完成
- 1% 的请求需要 3 秒

那么它的平均 RT 可能只有几十毫秒，看起来非常健康。

但对于用户来说，那 1% 的请求就是：

- 页面卡死 
- 接口超时
- 操作失败
- 投诉出现

从用户视角看，系统是“有问题的”。

这也是为什么在真正的高并发系统中，工程师更关心：

- P95
- P99
- 甚至 P999

因为这些指标反映的不是“系统大多数时候怎么样”，而是——**系统最糟糕的时候会发生什么**。

而高并发，往往就是在这些最糟糕的时刻出现的。

## QPS 掩盖了一个更关键的问题：系统是否可控

当我们只盯着 QPS 的时候，很容易忽略一个更重要的问题度：当系统开始变慢时，你是否还有控制权？

一个真正危险的系统，往往具备以下特征：

- 请求持续涌入
- 没有限流
- 没有拒绝策略
- 没有降级
- 没有超时
- 没有熔断

这种系统在低负载下看起来 “性能很好”，但一旦超过临界点，就会迅速进入不可逆的崩溃状态。

而一个成熟的系统，反而会在 “扛不住之前” 就主动示弱：

- 主动丢弃非核心请求
- 主动降低服务质量
- 主动延迟处理
- 主动返回兜底策略

这也是为什么说：**高并发系统拼的不是极限性能，而是失控之前的自我保护能力**。

## 回到本质：QPS 只是结果，不是能力  

> QPS 不是系统能力的体现，它只是系统状态的一个结果。

真正决定系统能否承受高并发的，从来不是一个数字，而是：

- 你的请求是否可以被削峰
- 你的链路是否足够短
- 你的失败是否可控
- 你的系统是否知道什么时候该放弃

也正因为如此，脱离业务背景谈 QPS，本身就是一种误导。

# 三、我们到底在衡量什么？

如果说上一节是在拆掉“QPS 等于高并发”的错觉，那么这一节要做的事情只有一个：

> **把“高并发”从一个模糊的印象，拆解成几个可以被真正理解的工程指标。**

因为在真实系统中，没有任何一个工程师是靠一个数字在做决策的。

真正影响系统设计的，是一组彼此制约、相互影响的指标。

而 QPS，只是其中最表层的一个。

## 并发

很多人会把“并发”理解成一种能力：“这个系统能抗多少并发？”

但在工程语境下，并发从来不是能力，而是一种**状态**。

它描述的不是系统能做什么，而是——**此时此刻，系统里有多少请求还没处理完。**

这也是为什么并发这个词，本质上永远和三件事绑定在一起：

- 活跃请求数
- 资源占用情况
- 上下文切换成本

每一个没有完成的请求，都会实实在在地占用资源：一个 goroutine、一段内存、一次数据库连接、一次锁竞争。

所以，并发高不高，决定的不是系统“能处理多少请求”，而是——**系统同时要扛住多少压力。**

这也是为什么可以说：

> **并发决定了你需要多少资源，而不是你能处理多少请求。**

一个系统完全可能 QPS 不高，但并发极高；也完全可能 QPS 很高，但并发始终可控。

真正拉开差距的，从来不是“请求总量”，而是“请求在系统里停留多久”。

## RT / P99：被忽视的核心指标

如果说并发是系统的“承压状态”，

那 RT（响应时间）就是这个状态最直观的外在表现。

但问题在于，大多数人谈 RT，只看平均值。

平均值是一个非常“温柔”的指标，它会抹平所有问题。

一个系统哪怕存在少量 2 秒、3 秒的慢请求，只要比例足够低，平均 RT 看起来依然会很漂亮。

可现实是——用户体验从来不是由平均值决定的。

当用户觉得系统“卡了”，往往不是因为它慢了 10ms，而是因为某一次请求突然卡住了。

这也是为什么在高并发系统里，真正有意义的指标是：

- P95    
- P99    
- 甚至 P999    

它们代表的是：**在最糟糕的情况下，系统还能不能接受。**

很多系统的失败，并不是因为整体性能不够好，而是因为极少数请求把资源拖死了。

所以才会有这样一句话：

> 系统不是慢在平均值，而是死在极端值。
> 用户感知的从来不是 P50，而是那一次卡死。

当你开始关注 P99，而不是平均 RT 时，你才真正开始站在“系统稳定性”的视角看问题。

## TPS：业务视角下的真实指标

如果说 QPS 更偏技术视角，那么 TPS 更接近业务视角。

QPS 统计的是接口调用次数，而 TPS 统计的，是**业务动作的完成次数**。

一个下单操作，可能包含：

- 参数校验    
- 库存检查
- 价格计算
- 订单写库
- 消息投递
- 状态回调

从 QPS 角度看，这是多个请求；但从业务角度看，它只是一次交易。

这也是为什么在复杂系统中，单纯讨论 QPS 往往没有意义。

因为你永远无法从一个 QPS 数字中，看出：

- 一次请求背后调用了多少服务    
- 消耗了多少数据库资源
- 触发了多少异步逻辑

所以才会有这样一个更贴近现实的判断方式：

  > QPS 描述接口，TPS 描述业务。
> 一个 TPS 背后，往往是多个接口、多个系统的协作。

当你开始用 TPS 去思考问题时，你关注的就不再是“接口快不快”，而是“这件事做完要付出多大代价”。

这本身，就是一种视角的升级。

## 吞吐、并发、延迟的关系

如果把系统比作一条公路，那么这三个概念的关系其实非常直观：

- 吞吐量，是单位时间通过的车辆数    
- 并发数，是路上同时存在的车辆
- 延迟，是从上路到下路花的时间

你可以让路很宽，让车跑得多；也可以让车开得很快，但路上车不多；但你很难在资源有限的情况下，同时做到三者都极致。

这也是很多系统在高负载下表现异常的根本原因。

  当吞吐被不断推高，而并发又持续累积时，延迟就会开始不可控地上升。

于是你会看到一个非常典型的现象：

- 系统“还能用”    
- QPS“还能跑”
- 但用户体验已经明显下降

这并不是偶然，而是系统到达物理边界后的必然结果。

所以才会有这样一句话：

> 吞吐是车流量，并发是路上的车，延迟是堵车时间。
> 高吞吐的系统，不一定是低延迟的系统。

理解了这一点，你就会明白——所谓 “高并发系统设计”，本质上从来不是堆性能，而是管理拥堵。

# 四、真正的高并发来自哪里？

如果前面几个小节都是在拆概念，那门从这一节开始，我们要把视角拉回到现实的系统中。

一个很重要，但是经常被忽略的事实是：**绝大多数高并发问题，并不是“流量太大”了，而是“流量在不该集中的地方集中起来了”**。

换句话说，高并发往往不是自然产生的，而是被某种行为放大的结果。

## 用户行为带来的并发

在所有高并发的场景中，最容易被理解的，往往也是最容易被高估的，就是用户行为。

秒杀、抢购、活动开始瞬间，这些场景看起来天然和 “高并发” 绑定在一起。

但是你仔细想想，会发现一个很有意思的现象：这些场景的本质，并不是用户足够多，而是用户在同一时间在做同一件事。

人类的行为具有极强的同步性。

当一个活动被定义为“10 点开始”，那就意味着：

- 9:59 几乎没人点
- 10:00 大量请求同时涌入
- 10:01 热度迅速下降

从系统角度看，这是一种非常极端的访问模式：请求不是均匀分布的，而是被强行压缩到了一个极短的时间窗口内。

也正因为如此，这类场景才反复被拿来当作 “高并发” 的代表。

但是问题在于，这种并发其实是人为制造的。要解决这种问题，其实只需要稍微换一种方式，比如：

- 引入排队机制
- 提前发放资格
- 使用随机延迟
- 分批放量

你会发现，并发峰值会立刻下降一个数量级。

所以很多时候，高并发并不是技术问题，而是产品设计的问题。也正因如此，才会有这样一句话：**用户不会平均访问，他们只会一起点。**

## 系统行为制造的并发

如果说用户行为带来的并发还算 ”合理“，那真正危险的高并发，往往是系统自己。

这一点，在真实的线上事故中几乎是常态。最典型的，就是定时任务。

很多系统都会有这样的设计：

- 每天凌晨跑一次统计任务
- 每隔五分钟同步一次数据
- 定时扫描状态并触发处理
这些任务在设计时往往是独立的，但在运行时却可能同时触发。

当多个定时任务叠加在一起，就会形成一种非常隐蔽的并发高峰：

- 没有用户访问
- QPS 看起来不高
- 但是数据库、RPC、消息队列同时被打满

更危险的是重试机制。重试本身是为了提高成功率，但如果设计不当，它会变成并发放大的加速器：

- 下游慢 → 请求超时
- 上游开始重试
- 重试流量叠加原始流量
- 下游更慢
- 更多重试

最终形成 ”重试风暴“。

这类问题往往是非常致命的，因为它们具有两个特点：

- 不是突发，而是逐渐积累
- 一旦出现，很难快速止损

最可怕的并发，往往不是由用户操作造成的，而是系统自己制造的。

# 架构设计带来的放大效应

还有一类高并发问题，看起来像是流量问题，实际上是设计问题。

最常见的，就是过长的同步链路。

一个看似简单的请求，背后可能是：

- 网关 → 服务 A
- 服务 A → 服务 B
- 服务 B → 服务 C
- 服务 C → 数据库

只要其中任何一环变慢，整个链路的响应时间都会被拉长。

而一旦 RT 变长，并发就会自然上升。

这是一种非常典型的“放大效应”：

- 请求数没有增加    
- 用户没有变多
- 但系统压力却指数级上升

类似的问题还包括：
- 所有请求都走数据库，没有缓存 
- 所有逻辑同步执行，没有异步拆分
- 所有接口共享同一组资源池

这些设计在低负载下可能完全没问题，但一旦流量上来，就会暴露出本质问题。

这也是为什么很多所谓的“高并发问题”，最后定位下来会发现： 流量本身并不大，真正的问题在于系统结构不合理。

或者说得更直白一点：

  > 很多高并发问题，本质是设计问题，而不是流量问题。

# 五、高并发系统真正要解决的三个问题

在前面的章节里，我们已经反复提到一个事实：

> 高并发从来不是一个纯技术问题，而是一个工程问题。

如果你仔细回顾那些真正出过事故的系统，会发现一个很有意思的现象——  
它们往往不是“扛不住请求”，而是**不知道在什么时候该退让**。

也正因为如此，一个成熟的高并发系统，真正要解决的，从来不是“怎么更快”，而是下面这三个问题。

## 能不能慢一点？

在很多工程师的潜意识里，有一个几乎不被质疑的前提：请求来了，就必须立刻处理。

但这是一个非常危险的假设。

因为现实中的业务，并没有那么多“必须立刻完成”的操作。

你可以仔细想一下：

- 用户点击一个按钮，真的必须立刻写数据库吗？
- 一条日志，真的要同步落盘吗？
- 一个统计指标，晚几秒算出来会造成什么后果？
- 一次状态变更，是否可以异步通知？

在大多数业务场景中，答案其实都是：**不一定。**

而一旦你允许“慢一点”，系统设计的空间会瞬间被打开。

你可以把同步请求变成异步消息；
你可以把实时处理变成延迟处理；
你可以把高峰期的流量，摊平到更长的时间窗口。

这也是为什么很多看起来“扛住了高并发”的系统，本质上并不是更快了，而是更“耐心”了。

它们并没有和流量正面硬刚，而是通过削峰、缓冲、排队，让系统始终运行在一个安全区间内。

从工程角度讲，这是一种极其理性的选择。

因为真正危险的不是慢，而是**所有请求都要求立即完成**。

## 能不能失败？

这是另一个经常被忽略，但比性能本身更重要的问题。

很多系统在设计时，默认了一个隐含前提：只要请求来了，我就必须给出一个正确的结果。

这个前提在低并发下没问题，但在高并发场景中，它几乎必然导致灾难。

因为任何系统的资源都是有限的：

- 线程是有限的
- 连接是有限的
- CPU 是有限的
- IO 是有限的

当请求超过系统承载能力时，如果你仍然选择“硬撑”，结果往往只有一个：  
**所有请求一起失败。**

真正成熟的系统，恰恰相反，它们会非常坦然地面对失败，并且会精心设计失败的方式。

比如：

- 非核心功能可以直接降级
- 次要请求可以直接拒绝
- 可重试的操作允许失败后补偿
- 不重要的数据返回默认值

从用户视角看，这可能意味着：
- 页面少了一个模块
- 某个功能暂时不可用
- 数据不是最新的

但从系统视角看，这是一次成功的自我保护。

因为它用“局部失败”，换来了“整体可用”。

也正是基于这个思路，限流、熔断、降级这些机制才会成为高并发系统的标配，而不是锦上添花的装饰品。

换句话说：

> 高可用不是不失败，而是知道该让谁失败。


## 能不能在失控之前停下来？

这是最高级的一层，也是很多系统最欠缺的一层能力。

大量线上事故的真实过程，其实非常相似：

1. 某个依赖开始变慢  
2. 请求开始堆积  
3. 线程池逐渐打满  
4. 重试机制开始生效  
5. 流量被进一步放大  
6. 数据库或下游彻底崩溃  

从事后看，整个过程往往持续了好几分钟，甚至更久。

但系统在这个过程中，几乎没有做出任何“自我保护”的行为。

它既没有拒绝请求，也没有降级服务，更没有主动限速——  
它只是一直在努力工作，直到彻底撑不住为止。

这背后的问题不在于性能，而在于：  
**系统并不知道自己已经快到极限了。**

一个真正成熟的高并发系统，必须具备“自我感知能力”：

- 知道当前负载是否异常
- 知道哪些请求是非核心的
- 知道什么时候该拒绝新请求
- 知道如何保护核心链路

换句话说，它不是等别人来救，而是会主动踩刹车。

这也是为什么在真正的高并发架构中，“保护系统”本身就是一等公民。

## 高并发的本质，其实是一种工程取舍

当你把这三个问题放在一起看，会发现一个非常重要的转变：

我们讨论的已经不再是：

- 用什么中间件
- 能扛多少 QPS
- 性能还能不能再榨一点

而是在讨论：

- 什么请求值得被认真对待
- 什么结果可以被延迟
- 什么失败是可以接受的
- 系统的边界在哪里

也正是在这个层面上，高并发才真正从“技术问题”，变成了“工程问题”。

你会发现，真正稳定的系统，往往都有一个共同特征：

它们从一开始，就没打算赢下所有请求。

而是选择在合适的时候退一步，保住最重要的部分。

这也是为什么说：

> 高并发系统不是靠更强活下来的，而是靠更克制。

# 六、从工程角度看，高并发的解决手段

如果前面几章解决的是“认知问题”，那么从这一章开始，我们要把视角真正拉回工程本身。

但在进入具体方案之前，有一个非常重要的前提必须先说清楚：

> 高并发不是靠某一个技术解决的，而是靠一整套设计思想兜住的。

很多人在谈高并发时，习惯直接跳到：
- Redis
- MQ
- 分库分表
- 限流熔断

但如果不先想清楚“要解决什么问题”，这些技术只会变成堆叠出来的复杂度。

所以这一节，我们不从工具讲起，而是从**工程目标**讲起。

## 先说结论：高并发系统只做三件事

从工程角度看，一个成熟的高并发系统，最终只在做三件事：

1. **减少必须同步处理的事情**
2. **限制系统同时处理的事情**
3. **保证核心链路优先活下来**

几乎所有高并发设计手段，都可以归到这三类里。

## 减少必须同步处理的事情

这是最根本、也是收益最高的一步。

因为同步请求的本质是： **请求不返回，资源就不能释放**。

这意味着它天然会放大并发。

所以高并发系统的第一原则是：  **能异步的，一定不要同步。**

常见的工程手段包括：

- 把写操作变成消息投递
- 把强一致改成最终一致
- 把实时计算改成延迟计算
- 把用户等待变成后台处理

这些改造看起来像是在“牺牲体验”，但实际上是在用可接受的延迟，换取系统整体的稳定性。

很多所谓“扛住了高并发”的系统，本质上只是把请求变成了：

> 先收下，再慢慢处理。

从用户角度看，体验并没有明显变差；  
从系统角度看，压力却被极大地削平了。

## 限制系统同时处理的事情

这是第二层防线，也是很多系统真正开始“变稳”的地方。

因为无论你的机器多强、架构多复杂，有一个事实无法改变：**系统的并发处理能力一定是有上限的**。

如果请求不加限制地进入系统，最终结果只会是：
- 线程打满
- 连接耗尽
- RT 飙升
- 整体雪崩

所以成熟系统一定会主动做“限制”。

这类设计通常体现在：

- 线程池大小是有限的
- 请求队列有长度上限
- 超过阈值直接拒绝
- 重要接口和普通接口隔离

这里有一个非常反直觉但非常重要的认知：拒绝请求，本身就是一种保护机制。

一个敢于拒绝请求的系统，往往比“什么都接”的系统稳定得多。

因为它至少保证了一件事： **系统不会在不可控的状态下继续恶化。**

## 保证核心链路优先活下来

当系统压力继续上升时，真正考验架构的，是“谁先死”。

一个设计良好的系统，从一开始就应该明确：

- 哪些是核心功能
- 哪些是非核心功能
- 哪些是可以牺牲的
- 哪些是绝不能挂的

这也是为什么在高并发系统中，经常能看到：

- 核心接口和非核心接口分池
- 核心服务独立部署
- 非核心功能可以直接降级
- 数据展示允许使用缓存或旧数据

这种设计的本质，是在系统内部建立“优先级”。

当资源紧张时：
- 非核心功能先让路
- 非关键请求先失败
- 核心链路保持可用

这听起来很残酷，但它是系统在极端情况下唯一理性的选择。

## 为什么说高并发设计，本质是“工程取舍”？

当你把上面的内容串起来，会发现一个很有意思的事实：

我们几乎从来没有讨论过“怎么把性能做到极致”。

我们讨论的始终是：
- 哪些可以慢
- 哪些可以失败
- 哪些必须保住
- 哪些要提前放弃

这也是为什么很多经历过真实高并发场景的工程师，最终都会达成一个共识：

> 高并发系统不是设计出来的，是被现实逼出来的。

它不是靠某个中间件解决的，  也不是靠某种架构模式一劳永逸解决的，  而是在一次次取舍中逐渐演化出来的。

真正成熟的系统，往往看起来并不“酷”，但它们有一个共同点：

**在任何时候，都知道自己在做什么，也知道自己不能做什么。**

# 七、回到现实：如何在面试中正确回答“高并发”问题？

如果你看到这里，大概已经会有一个很强烈的感受：

> 高并发从来不是一个技术题，而是一道认知题。

但现实是，面试官并不会问你这些宏观问题。  
他们通常只会抛出一句非常模糊、但杀伤力极强的问题：

- “如果系统 QPS 突然涨到 10 万，你怎么办？”
- “秒杀场景你会怎么设计？”
- “数据库扛不住了怎么处理？”

很多人一听到这种问题，第一反应就是开始堆技术名词：

- 上缓存  
- 上 MQ  
- 分库分表  
- 限流熔断  
- 加机器  

看起来很专业，但实际上，这种回答很容易踩坑。

因为你在回答一个**没有前提的问题**。

## 面试官真正想问的，其实不是“你会不会做”

先说一个非常现实的结论：

> 面试官问高并发，几乎从来不是想听一个“标准架构”。

他们真正想确认的，是下面这几件事：

- 你会不会先分析问题，而不是直接给方案  
- 你知不知道系统的瓶颈在哪里  
- 你有没有“工程视角”，而不是只会背技术名词  
- 你是否理解取舍，而不是追求完美  

换句话说，他们想看的不是你“知道多少技术”，而是你**在不确定场景下的思考方式**。

## 一个高质量回答，应该长什么样？

一个成熟的回答，通常会遵循一个非常稳定的结构：

### 第一步：先澄清场景，而不是直接给方案

你可以先反问，或者主动补充前提，比如：

- 这是读多还是写多的场景？
- 是突发流量还是长期高负载？
- 是否允许延迟？是否允许失败？
- 是核心链路还是辅助功能？

这一步非常重要，因为它直接决定了后续设计方向。

这时你传递给面试官的信息是：

> 我不会在信息不完整的情况下乱设计系统。

### 第二步：把问题拆成“压力从哪来”

你可以顺着前面文章的思路，把问题拆成：

- 是用户集中访问造成的？
- 还是系统内部任务叠加？
- 是 RT 变长导致的并发上升？
- 还是下游服务成为瓶颈？

这一步的目的不是给答案，而是展示你具备“定位问题”的能力。

面试官往往在这里就已经能判断你是否有真实经验。

### 第三步：给出分层思路，而不是一个答案

一个很加分的方式是，把解决方案分成几个层次：

- 从业务层看，能不能削峰、延迟、异步
- 从系统层看，能不能限流、隔离、降级
- 从架构层看，是否需要解耦、拆分
- 从极端情况看，如何兜底和止损

注意：这里的重点不是你说了多少技术，而是你有没有清晰的“优先级”。

真正成熟的工程师，永远不会一上来就说“上 MQ”。

## 一个参考回答（思路版）

下面是一个你可以直接在面试中使用的回答结构，逻辑非常稳：

> “我一般会先确认这个高并发场景是否真实存在，比如是活动流量、用户行为集中，还是系统自身造成的。
>
> 如果是突发流量，我会优先考虑削峰和限流，而不是直接扩容。
>
> 然后我会看这个请求是否必须同步完成，能不能异步化或者延迟处理。
>
> 如果确实是核心链路，我会考虑通过缓存、隔离、降级来保护主流程。
>
> 最后才会评估是否需要做更重的架构改造，比如拆服务或者引入 MQ。”

这个回答有一个非常重要的特点：

**你没有承诺“我一定能扛住”，而是在说明“我知道怎么不把系统搞死”。**

这在真实工程里，比“我能抗百万 QPS”要有价值得多。

## 一个容易被忽略的加分点：你是否提到了“代价”

很多人回答高并发问题时，会犯一个共同的错误：

只讲收益，不讲代价。

但在真实工程中，每一个优化都有成本：

- 引入 MQ，意味着一致性复杂度上升
- 加缓存，意味着数据一致性变差
- 分库分表，意味着运维和开发成本暴增
- 限流降级，意味着用户体验下降

如果你能在回答中主动提到这些 trade-off，面试官会立刻意识到：

> 你不是在背答案，而是真的做过取舍。

这往往是“普通候选人”和“高级工程师”的分水岭。

## 最后一个关键认知

如果你只记住这一章的一句话，那应该是这句：

> 高并发问题，从来不是“怎么扛住”，而是“什么时候该停下来”。

系统的成熟，不体现在它能承受多大的压力，  而体现在它能否在失控之前，主动做出正确选择。

这也是为什么，真正厉害的系统看起来往往很“克制”，但也正是这种克制，让它们活得足够久。

# 八、总结：高并发不是技术问题，而是认知问题

写到这里，其实已经可以回头看一眼我们最开始提出的那个问题：

> 为什么我们总在谈高并发？

你会发现，真正的问题从来不是“并发有多高”，而是——**我们到底在用什么方式理解系统。**

在这篇文章里，我们没有刻意去讲：
- 如何支撑百万 QPS  
- 如何设计秒杀系统  
- 如何搭建复杂架构  

不是因为这些不重要，而是因为——  **如果认知层面错了，技术堆得再多也没有意义。**

## 写在最后

面试里问“秒杀系统怎么设计”，很多时候并不是想听你把 Redis、MQ、分库分表都背一遍。  
它更像是在用一个极端场景，测试你是否具备一种能力：**在信息不完整的情况下，先建立边界，再做取舍。**

所以我会这样回答这个问题——不是给出唯一架构，而是给出一套能落地、可演进的设计路径。

### 1）先把“秒杀”拆成几个必须回答的业务前提

我会先澄清这几件事，因为它们决定了系统形态：

- 目标峰值是突发还是持续？持续多久？
- 商品数量、单用户限购规则、是否允许“排队后失败”？
- 是否允许少量超卖？允许到什么程度？
- 是否必须强一致（库存、订单、支付），还是可以最终一致？
- 成功后的链路是“创建订单即成功”，还是“支付成功才算成功”？

这一步的目的不是刁难面试官，而是把“秒杀”从一句口号变成可设计的系统。

### 2）秒杀系统真正要解决的核心矛盾：把“洪峰”变成“可控队列”

秒杀的本质不是流量大，而是**用户在同一时刻一起点**。  
所以设计目标应该是：**削峰、限流、排队**，让系统不被瞬时并发拖死。

我的总体策略是三句话：

- **入口处先限住**（不让无意义的请求进来）
- **核心链路尽可能短**（让请求尽快结束、资源尽快释放）
- **写操作异步化**（把“实时压力”转成“可处理的积压”）

### 3）分层设计：从入口到数据层，层层“减压”

#### 3.1 接入层：先把无效请求挡在系统外

入口层的目标不是“算得更快”，而是“别让系统做无意义的事”。

常见手段包括：

- CDN 静态化：活动页、商品页尽量静态化，减少回源
- 网关限流：按照 IP / 设备 / 用户维度限流（令牌桶/漏桶都行）
- 黑白名单与风控：拦截脚本、异常频率、可疑 UA
- 登录态校验与权限预检：别让未登录/无资格用户打到核心链路

这里的核心思想是：**秒杀的竞争，不应该发生在数据库上，而应该发生在更靠前的位置。**

#### 3.2 应用层：把“抢”变成“排队”，把同步写变成异步写

应用层我会做两件事：

**第一，把资格和规则前置**  
例如：限购、活动时间窗口、用户是否有资格，都尽量在缓存/本地完成判断，避免每次落 DB。

**第二，把下单变成“拿号”**  
用户点一次，不一定立刻创建订单，而是先进入排队或拿到一个“请求受理”的结果：

- 返回“排队中/处理中”的状态
- 或者返回一个 token（排队凭证/下单凭证）

这一步的核心收益是：系统不用在同一时刻完成所有写入，只要能稳定接住请求，并有序处理即可。

#### 3.3 缓存与库存：库存扣减要“快”，但更要“可控”

库存扣减一般不会直接落库硬扣，因为那会把 DB 直接打穿。  
更常见做法是：**缓存中扣减 + 异步落库 + 失败补偿**。

典型实现是：

- Redis 作为库存的快速判断与扣减（原子操作）
- 扣减成功后写入消息队列，异步创建订单/落库
- 落库失败进行补偿（回补库存、标记失败）

这里我会强调两个工程点：

- 必须保证扣减操作的原子性（避免并发超卖）
- 必须考虑“最终一致”的补偿策略（异步链路必然会失败）

如果业务要求极强一致且不能超卖，那成本会显著变高：  
可能需要引入更强的事务语义或更重的锁，但通常秒杀业务会接受可控的不完美。

#### 3.4 消息队列：让系统“慢一点”，但一直可用

MQ 在秒杀里承担的角色不是“更高级”，而是“更稳定”：

- 削峰：把洪峰转成队列长度
- 解耦：下单与支付/通知/发券等非核心链路解耦
- 可恢复：系统抖动时队列可积压，恢复后继续消费

但我也会主动说清楚代价：

- 引入 MQ 就要处理重复消息、顺序性、消费幂等等问题
- 系统复杂度上升，需要更完善的监控与告警

这会让面试官更相信你做过取舍。

#### 3.5 数据层：最终落库要抗住“可控写入”，而不是“无限洪峰”

秒杀最终仍要落库，但落库时已经是“被削峰后的流量”：

- 批量写入（如果业务允许）
- 写库分片（必要时）
- 订单表按时间/用户维度做合理索引
- 读写分离用于查询类请求（例如“我是否抢到”）

核心思想是：  
**DB 扛的是稳定写入，不是瞬时洪峰。**

### 4）稳定性设计：扛不住的时候怎么体面地“失败”

如果面试官只听到你讲“怎么成功”，而没听到你讲“怎么失败”，这个回答通常是不完整的。

我会明确说：

- 非核心功能降级：比如活动推荐、埋点、风控细项可降级
- 返回兜底：系统过载时直接返回“活动太火爆，请稍后重试”（但要配合限流，避免重试风暴）
- 熔断与超时：下游慢就熔断，避免同步链路拖死
- 队列长度上限：超过上限直接拒绝，避免无止境积压把系统拖垮

这其实是在呼应整篇文章的核心观点：  
**高并发系统拼的不是极限性能，而是失控前的自我保护能力。**

### 5）一致性与幂等：秒杀系统的“隐藏主线”

秒杀设计里最容易被忽略的是：  
即使你削峰、限流、异步都做了，系统依然会面对大量不可避免的问题：

- 用户重复点击、重试导致的重复请求
- 消息重复投递导致的重复下单
- 网络抖动导致的乱序到达

所以我会补一句“落地工程必须做”的东西：

- 请求幂等：用户维度的幂等键（user_id + sku_id + activity_id）
- 订单幂等：订单创建幂等（唯一索引/幂等表）
- 消息幂等：消费者端去重（幂等表/状态机）
- 状态机：订单状态可回溯、可补偿

这一步往往是区分“背过答案”与“真的做过系统”的分水岭。

---

### 用一句话收尾（也是这篇博客的最后一句）

当我被问“怎么设计秒杀系统”时，我想传达的不是某个固定架构，而是一个核心思想：

> 秒杀不是把系统做得更强，而是把洪峰变得可控；  
> 高并发不是技术堆叠，而是边界清晰、取舍明确、失控可止。

这就是我对“高并发”的理解，也是这篇文章想留下些什么的东西。